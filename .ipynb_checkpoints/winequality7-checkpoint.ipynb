{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from matplotlib import style\n",
    "import math\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "# Algorithms\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,roc_curve,roc_auc_score\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine=pd.read_csv(\"winequality.csv\")\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the number of rows and columns\n",
    "print(\"Rows, columns: \" + str(wine.shape))\n",
    "\n",
    "# See the first five rows of the dataset\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.rename(columns= {'fixed acidity': 'fixed_acidity', 'volatile acidity': 'volatile_acidity', 'citric acid': 'citric_acid', 'residual sugar': 'residual_sugar', 'free sulfur dioxide': 'free_sulfur_dioxide','total sulfur dioxide': 'total_sulfur_dioxide' }, inplace=True)\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the data there is no categorical variables to study but we have all numerical variables\n",
    "# 11 of the features are floats, 1 is integers.\n",
    "wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of unique values in this dataset\n",
    "\n",
    "for col in wine.columns.values:\n",
    " print(\"Number of unique values of {}:{}\".format(col,wine[col].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Describe the dataset to get a better idea on what's happening\n",
    "wine.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "Chlorides - Mininmum of 0.012, Maximum of 0.611 meaning some wines are really salty\n",
    "\n",
    "Residual sugar - Minimu of 0.9, Maximum of 15.5. Some wines are really sweet\n",
    "\n",
    "Fixed acidity ranges from 25% - 7.1 and 50% - 7.9. This could explain the huge number of outliers\n",
    "\n",
    "pH - some wines are much more acid than others\n",
    "\n",
    "The mean is more than median (50th percentile) in all columns\n",
    "\n",
    "There is a large difference in 75% percentile and max in residual sugar,free sulfur dioxide,total sulfur dioxide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of outliers within the data\n",
    "collist=wine.columns.values\n",
    "ncol=12\n",
    "nrows=10\n",
    "plt.figure(figsize=(ncol,5*ncol))\n",
    "for i in range(0,len(collist)):\n",
    " plt.subplot(nrows,ncol,i+1)\n",
    " sns.boxplot(wine[collist[i]],color='green',orient='v')\n",
    " plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Distribution of Skewness\n",
    "# plt.figure(figsize=(20,20))\n",
    "# for i in range(0,len(collist)):\n",
    "#  plt.subplot(nrows,ncol,i+1)\n",
    "#  sns.distplot(wine[collist[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Missing Values\n",
    "print(wine.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data looks very clean by looking at the first five rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram for the 'quality' variable making sure there is enough good quality wine\n",
    "fig = px.histogram(wine,x='quality')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "    \n",
    "Quality has most values concentrated in the categories of 5,6,7\n",
    "\n",
    "Fewer values are concentrated in the categories of 3,4 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = wine.corr()\n",
    "plt.subplots(figsize=(15,10))\n",
    "sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, annot=True, cmap=sns.diverging_palette(220, 20, as_cmap=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr['quality'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "    \n",
    "Quality is highly correlated with alcohol\n",
    "\n",
    "Alcohol is negatively correlated with density -0.5\n",
    "\n",
    "Density is highly positively correlated with fixed acidity\n",
    "\n",
    "Volatile acidity is negatively correlated with quality and citric acid\n",
    "\n",
    "Free sulphuric acid is highly correlated with total sulfur dioxide\n",
    "\n",
    "Conclusion can be made that the attributes alcohol, sulphates, citric acid, fixed acidity have maximum correlation with 'quality'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Classification version of target variable\n",
    "wine['rating'] = [1 if x >= 6 else 0 for x in wine['quality']]\n",
    "\n",
    "# Good quality becomes 1 and Bad quality becomes 0\n",
    "\n",
    "# Separate feature variables and target variable\n",
    "#X = wine.iloc[:,:11]\n",
    "X = wine.drop(['quality','rating'], axis = 1)\n",
    "y = wine['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See proportion of good vs bad wines\n",
    "wine['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.groupby('rating').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of alcohol percentage with wine quality\n",
    "bx = sns.boxplot(x=\"quality\", y='alcohol', data = wine)\n",
    "bx.set(xlabel='Wine Quality', ylabel='Alcohol Percent', title='Alcohol percent in different wine quality types')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation\n",
    "\n",
    "Alcohol content increases as the quality of wine increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of pH & wine ratings\n",
    "bx = sns.swarmplot(x=\"rating\", y=\"pH\", data = wine);\n",
    "bx.set(xlabel='Wine Ratings', ylabel='pH', title='pH in different types of Wine ratings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis of sulphates & wine ratings\n",
    "bx = sns.boxplot(x=\"rating\", y='sulphates', data = wine)\n",
    "bx.set(xlabel='Wine Ratings', ylabel='Sulphates', title='Sulphates in different types of Wine ratings')\n",
    "\n",
    "# Sulphates level increases with the quality of wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis of Citric Acid & wine ratings\n",
    "bx = sns.violinplot(x=\"quality\", y='citric_acid', data = wine)\n",
    "bx.set(xlabel='Quality', ylabel='Citric Acid', title='Citric_acid in different types of Wine ratings')\n",
    "\n",
    "#Citric acid increases as quality of the wine increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of fixed acidity & wine ratings\n",
    "bx = sns.boxplot(x=\"rating\", y='fixed_acidity', data = wine)\n",
    "bx.set(xlabel='Wine Ratings', ylabel='Fixed Acidity', title='Fixed Acidity in different types of Wine ratings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plots\n",
    "sns.FacetGrid(wine,hue='rating',height=6).map(sns.distplot,'alcohol').add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation\n",
    "\n",
    "\n",
    "\n",
    "There is a higher probability of good quality wine, if alcohol content is >= 12\n",
    "\n",
    "The probability of good quality wine decreases as alcohol content decreases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "# The graph below shows a linear regression between residual sugar and alcohol content for different quality ratings(bad, good)\n",
    "sns.lmplot(x = 'alcohol', y = 'residual_sugar', col = 'rating', data = wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "Observation\n",
    "\n",
    "An observation can be made that in both types of wine the residual sugar content remains almost the same irrespective of change in alcohol content value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize feature variables and apply Standard Scaling to get optimized result\n",
    "sc=StandardScaler()\n",
    "X_features = X\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# model1 = DecisionTreeClassifier(random_state=1)\n",
    "# model1.fit(X_train, y_train)\n",
    "# y_pred1 = model1.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Machine Learning Algorithms\n",
    "\n",
    "lg=LogisticRegression()\n",
    "gnb = GaussianNB()\n",
    "\n",
    "#prepare models\n",
    "models=[]\n",
    "models.append(('LogisticRegression',lg))\n",
    "models.append(('Naive Bayes',gnb))\n",
    "\n",
    "#evaluate each model\n",
    "Model=[]\n",
    "cvs=[]\n",
    "score=[]\n",
    "rocscore=[]\n",
    "for name,model in models:\n",
    " print('**************',name,'***********')\n",
    " print('\\n')\n",
    " Model.append(name)\n",
    " model.fit(X_train,y_train)\n",
    " print(model)\n",
    " predictions=model.predict(X_test)\n",
    " print('\\n')\n",
    " acc=accuracy_score(y_test,predictions)\n",
    " print('accuracy score',acc)\n",
    " score.append(acc*100)\n",
    " cv=model_selection.cross_val_score(model,X,y,cv=10,scoring='accuracy').mean()\n",
    " print('Cross-val-score=',cv)\n",
    " cvs.append(cv*100)\n",
    " print('\\n')\n",
    " false_positive_rate,true_positive_rate,thresholds=roc_curve(y_test,predictions)\n",
    " roc_auc=roc_auc_score(y_test,predictions)\n",
    " print('roc_auc_score',roc_auc)\n",
    " rocscore.append(roc_auc*100)\n",
    " print('\\n')\n",
    " print(classification_report(y_test,predictions))\n",
    " print('\\n')\n",
    " cm=confusion_matrix(y_test,predictions)\n",
    " print(cm)\n",
    " print('\\n')\n",
    " plt.figure(figsize=(10,15))\n",
    " plt.subplot(911)\n",
    " plt.title(name)\n",
    " print(sns.heatmap(cm,annot=True))\n",
    " plt.subplot(912)\n",
    " plt.title(name)\n",
    " plt.plot(false_positive_rate,true_positive_rate,label='AUC'%roc_auc)\n",
    " plt.plot([0,1],[0,1],'k--')\n",
    " plt.xlabel('false_positive_rate')\n",
    " plt.ylabel('true_positive_rate')\n",
    " plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting Best Model:\n",
    "\n",
    "From above table we can observe the accuracy for Logistic Regression is 76% compared to Naive Bayes, 74%.This looks like a good score.\n",
    "\n",
    "Logistic Regression model has a higher Cross-val-score of 73%.\n",
    "\n",
    "Overall performance of either of the Logistic Regression algorithm is good.\n",
    "\n",
    "Receiver Operating Characteristic(ROC) curve is a plot of the true positive rate against the false positive rate. It shows the tradeoff between sensitivity and specificity.\n",
    "\n",
    "AUC(Area Under Curve) score for the case is 0.75. AUC score 1 represents perfect classifier, and 0.5 represents a worthless classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show Mean Absolute Error, Mean Squared Error & Root Mean Squared Error \n",
    "from sklearn import metrics\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show R squared value for regression\n",
    "print('R squared value: ',lg.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation\n",
    "print('Correlation: ', math.sqrt(lg.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = lg.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_predicted)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True positive is 135(34%), false negative is 50(12%)\n",
    "# False positive is 48(12%), true negative, 167(42%)\n",
    "\n",
    "# true positives: These are cases in which we predicted yes and are actually yes.\n",
    "# true negatives: We predicted no, and no in actual.\n",
    "# false positives: We predicted yes, but actual is no. (Type I error)\n",
    "# false negatives: We predicted no, yes in actual. (Type II error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting Values Logistic Regression\n",
    "lg.fit(X_train,y_train)\n",
    "predictions=lg.predict(X_test)\n",
    "print('predicted :',predictions)\n",
    "print('actual',y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lg.predict(X_test)\n",
    "pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "#use the loaded model to make prediction\n",
    "result = loaded_model.predict(X_test)\n",
    "result_accuracy = loaded_model.score(X_test, y_test)\n",
    "\n",
    "print(result)\n",
    "print(result_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An estimate of 74% the accuracy of the model on unseen data is reported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model using joblib\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "#save the model in a file\n",
    "joblib.dump(lg,'finalized_model_joblib.obj')\n",
    "\n",
    "#load the model from a file\n",
    "lg_from_joblib=joblib.load('finalized_model_joblib.obj')\n",
    "\n",
    "#use the loaded model to make prediction\n",
    "result = lg_from_joblib.predict(X_test)\n",
    "result_accuracy = lg_from_joblib.score(X_test, y_test)\n",
    "\n",
    "print(result)\n",
    "print(result_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering DataFrame for only good quality\n",
    "wine_good = wine[wine['rating']==1]\n",
    "wine_good.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that good quality wines have:\n",
    "\n",
    "higher levels of alcohol on average\n",
    "lower volatile acidity on average \n",
    "Higher levels of sulphates on average\n",
    "higher levels of residual sugar on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering Dataframe for only bad quality\n",
    "wine_bad = wine[wine['rating']==0]\n",
    "wine_bad.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MLP for Pima Indians Dataset Serialize to JSON and HDF5\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n",
    "import numpy\n",
    "import os\n",
    "# # fix random seed for reproducibility\n",
    "# numpy.random.seed(7)\n",
    "# # load pima indians dataset\n",
    "# dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# # split into input (X) and output (Y) variables\n",
    "# X = dataset[:,0:8]\n",
    "# Y = dataset[:,8]\n",
    "# # create model\n",
    "# model = Sequential()\n",
    "# model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "# model.add(Dense(8, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "# # Compile model\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# # Fit the model\n",
    "# model.fit(X, Y, epochs=150, batch_size=10, verbose=0)\n",
    "# # evaluate the model\n",
    "# scores = model.evaluate(X, Y, verbose=0)\n",
    "# print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    " \n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " \n",
    "# later...\n",
    " \n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q pyyaml h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
